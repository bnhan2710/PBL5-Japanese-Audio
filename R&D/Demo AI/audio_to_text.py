# #!/usr/bin/env python3
# """
# Audio to Text - Chuy·ªÉn ƒë·ªïi file audio th√†nh script ti·∫øng Nh·∫≠t

# Ch·ª©c nƒÉng:
# 1. Convert 1 file: python3 audio_to_text.py file.mp3
# 2. Convert t·∫•t c·∫£: python3 audio_to_text.py output/mondai --batch

# Script s·∫Ω t·ª± ƒë·ªông:
# - T·∫°o file .txt c√πng t√™n v√† c√πng th∆∞ m·ª•c v·ªõi file .mp3
# - Qu√©t t·∫•t c·∫£ mondai v√† questions n·∫øu d√πng --batch
# - Gi·ªØ nguy√™n c·∫•u tr√∫c th∆∞ m·ª•c

# Author: PBL5 Team
# Version: 2.0
# """

# import whisper
# import sys
# import argparse
# import logging
# from pathlib import Path
# from typing import List, Optional

# # Setup logging
# logging.basicConfig(
#     level=logging.INFO,
#     format='%(asctime)s - %(levelname)s - %(message)s'
# )
# logger = logging.getLogger(__name__)


# def audio_to_text(audio_path: str, output_path: str = None, model = None, model_size: str = "base", quiet: bool = False) -> str:
#     """
#     Chuy·ªÉn file audio th√†nh text ti·∫øng Nh·∫≠t
    
#     Args:
#         audio_path: ƒê∆∞·ªùng d·∫´n file audio (mp3, wav, m4a, etc)
#         output_path: ƒê∆∞·ªùng d·∫´n file output (optional, m·∫∑c ƒë·ªãnh: c√πng t√™n .txt)
#         model: Whisper model ƒë√£ load (optional, ƒë·ªÉ t√°i s·ª≠ d·ª•ng)
#         model_size: Whisper model size n·∫øu ch∆∞a c√≥ model
#         quiet: ·∫®n output chi ti·∫øt
    
#     Returns:
#         Text ti·∫øng Nh·∫≠t
#     """
#     audio_file = Path(audio_path)
    
#     # Ki·ªÉm tra file t·ªìn t·∫°i
#     if not audio_file.exists():
#         raise FileNotFoundError(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {audio_path}")
    
#     # X√°c ƒë·ªãnh output path
#     if output_path is None:
#         # Ki·ªÉm tra n·∫øu file n·∫±m trong output/mondai ‚Üí gi·ªØ nguy√™n c√πng th∆∞ m·ª•c (batch mode)
#         # N·∫øu file n·∫±m ·ªü input/ ho·∫∑c n∆°i kh√°c ‚Üí ƒë∆∞a v√†o output/ (single file mode)
#         if "output" in str(audio_file.parent):
#             output_path = audio_file.with_suffix('.txt')
#         else:
#             # Single file mode: ƒë∆∞a v√†o th∆∞ m·ª•c output/
#             output_dir = Path("output")
#             output_dir.mkdir(exist_ok=True)
#             output_path = output_dir / audio_file.with_suffix('.txt').name
#     else:
#         output_path = Path(output_path)
    
#     if not quiet:
#         logger.info(f"üìù {audio_file.name} ‚Üí {output_path.name}")
    
#     # Load Whisper model n·∫øu ch∆∞a c√≥
#     if model is None:
#         if not quiet:
#             logger.info(f"üîÑ Loading Whisper model ({model_size})...")
#         model = whisper.load_model(model_size)
    
#     # Transcribe
#     result = model.transcribe(
#         str(audio_file),
#         language="ja",  # Japanese
#         task="transcribe",
#         initial_prompt="JLPT„ÅÆËÅ¥Ëß£ÂïèÈ°å„Åß„Åô„ÄÇÊñáËÑà„ÇíÁêÜËß£„Åó„ÄÅÂè•Ë™≠ÁÇπÔºà„ÄÇ„ÄÅÔºâ„ÇíÊ≠£„Åó„ÅèÂê´„ÇÅ„ÅüËá™ÁÑ∂„Å™Êó•Êú¨Ë™û„ÅßÊõ∏„ÅçËµ∑„Åì„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ",
#         verbose=False
#     )
    
#     # L·∫•y text
#     text = result["text"].strip()
    
#     # L∆∞u file
#     with open(output_path, "w", encoding="utf-8") as f:
#         f.write(text)
    
#     if not quiet:
#         logger.info(f"‚úÖ Saved: {output_path.relative_to(audio_file.parent.parent) if len(audio_file.parents) > 1 else output_path}")
    
#     return text


# def find_audio_files(base_dir: Path) -> List[Path]:
#     """
#     T√¨m t·∫•t c·∫£ file MP3 trong c·∫•u tr√∫c mondai
    
#     Args:
#         base_dir: Th∆∞ m·ª•c g·ªëc (output/mondai)
        
#     Returns:
#         List c√°c path ƒë·∫øn file MP3
#     """
#     audio_files = []
    
#     # T√¨m trong c·∫•u tr√∫c: mondai_X/mondai_X.mp3 v√† mondai_X/questions/question_Y.mp3
#     for mondai_dir in sorted(base_dir.glob("mondai_*")):
#         if not mondai_dir.is_dir():
#             continue
        
#         # File mondai ch√≠nh
#         mondai_file = mondai_dir / f"{mondai_dir.name}.mp3"
#         if mondai_file.exists():
#             audio_files.append(mondai_file)
        
#         # Files questions
#         questions_dir = mondai_dir / "questions"
#         if questions_dir.exists():
#             question_files = sorted(questions_dir.glob("question_*.mp3"))
#             audio_files.extend(question_files)
    
#     return audio_files


# def batch_convert(base_dir: str, model_size: str = "base") -> dict:
#     """
#     Convert t·∫•t c·∫£ file audio trong th∆∞ m·ª•c th√†nh text
    
#     Args:
#         base_dir: Th∆∞ m·ª•c ch·ª©a c√°c mondai
#         model_size: Whisper model size
        
#     Returns:
#         Stats: {'total': int, 'success': int, 'failed': int}
#     """
#     base_path = Path(base_dir)
    
#     if not base_path.exists():
#         raise FileNotFoundError(f"‚ùå Th∆∞ m·ª•c kh√¥ng t·ªìn t·∫°i: {base_dir}")
    
#     logger.info("="*60)
#     logger.info("üé¨ BATCH CONVERT - Audio to Text")
#     logger.info("="*60)
#     logger.info(f"üìÇ Scanning: {base_path}")
    
#     # T√¨m t·∫•t c·∫£ file audio
#     audio_files = find_audio_files(base_path)
    
#     if not audio_files:
#         logger.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file audio n√†o!")
#         return {"total": 0, "success": 0, "failed": 0}
    
#     logger.info(f"üìä Found {len(audio_files)} audio files")
#     logger.info("")
    
#     # Load model m·ªôt l·∫ßn duy nh·∫•t
#     logger.info(f"üîÑ Loading Whisper model ({model_size})...")
#     model = whisper.load_model(model_size)
#     logger.info("‚úÖ Model loaded")
#     logger.info("")
    
#     # Process t·ª´ng file
#     stats = {"total": len(audio_files), "success": 0, "failed": 0}
    
#     for i, audio_file in enumerate(audio_files, 1):
#         try:
#             logger.info(f"[{i}/{len(audio_files)}] Processing...")
#             audio_to_text(
#                 audio_path=str(audio_file),
#                 model=model,
#                 quiet=False
#             )
#             stats["success"] += 1
#             logger.info("")
            
#         except Exception as e:
#             logger.error(f"‚ùå Error: {e}")
#             stats["failed"] += 1
#             logger.info("")
    
#     # Summary
#     logger.info("="*60)
#     logger.info("‚ú® BATCH CONVERT COMPLETED")
#     logger.info("="*60)
#     logger.info(f"üìä Total files: {stats['total']}")
#     logger.info(f"‚úÖ Success: {stats['success']}")
#     logger.info(f"‚ùå Failed: {stats['failed']}")
#     logger.info("="*60)
    
#     return stats


# def main():
#     """
#     Main entry point
    
#     Usage:
#     1. Convert 1 file:
#       python3 audio_to_text.py audio.mp3
#       python3 audio_to_text.py audio.mp3 script.txt
#       python3 audio_to_text.py audio.mp3 --model small

#     2. Convert t·∫•t c·∫£ (batch):
#       python3 audio_to_text.py output/mondai --batch
#       python3 audio_to_text.py output/mondai --batch --model small

#     C·∫•u tr√∫c output:
#       output/mondai/
#       ‚îú‚îÄ‚îÄ mondai_1/
#       ‚îÇ   ‚îú‚îÄ‚îÄ mondai_1.mp3
#       ‚îÇ   ‚îú‚îÄ‚îÄ mondai_1.txt    ‚Üê Script t·ª± ƒë·ªông t·∫°o
#       ‚îÇ   ‚îî‚îÄ‚îÄ questions/
#       ‚îÇ       ‚îú‚îÄ‚îÄ question_1.mp3
#       ‚îÇ       ‚îú‚îÄ‚îÄ question_1.txt    ‚Üê Script t·ª± ƒë·ªông t·∫°o
#       ‚îÇ       ‚îî‚îÄ‚îÄ ...
#       ‚îî‚îÄ‚îÄ ...

#     Model sizes:
#       tiny   - Nhanh nh·∫•t, ƒë·ªô ch√≠nh x√°c trung b√¨nh
#       base   - C√¢n b·∫±ng t·ªëc ƒë·ªô v√† ƒë·ªô ch√≠nh x√°c (khuy·∫øn ngh·ªã)
#       small  - Ch·∫≠m h∆°n, ch√≠nh x√°c h∆°n
#       medium - R·∫•t ch√≠nh x√°c, kh√° ch·∫≠m
#       large  - Ch√≠nh x√°c nh·∫•t, r·∫•t ch·∫≠m
#     """
#     parser = argparse.ArgumentParser(
#         description="Chuy·ªÉn file audio th√†nh script ti·∫øng Nh·∫≠t",
#         formatter_class=argparse.RawDescriptionHelpFormatter,
#         epilog=main.__doc__
#     )
    
#     parser.add_argument(
#         "path",
#         help="File audio ho·∫∑c th∆∞ m·ª•c (v·ªõi --batch)"
#     )
#     parser.add_argument(
#         "output_file",
#         nargs="?",
#         default=None,
#         help="File output cho single file (optional)"
#     )
#     parser.add_argument(
#         "--batch",
#         action="store_true",
#         help="Batch mode: convert t·∫•t c·∫£ file trong th∆∞ m·ª•c"
#     )
#     parser.add_argument(
#         "--model",
#         default="small",
#         choices=["tiny", "base", "small", "medium", "large"],
#         help="Whisper model size (default: small)"
#     )
    
#     args = parser.parse_args()
    
#     try:
#         if args.batch:
#             # Batch mode
#             stats = batch_convert(
#                 base_dir=args.path,
#                 model_size=args.model
#             )
#             return 0 if stats["failed"] == 0 else 1
            
#         else:
#             # Single file mode
#             print("="*60)
#             print("üé¨ AUDIO TO TEXT - JLPT Script Generator")
#             print("="*60)
#             print()
            
#             # Load model
#             print(f"üîÑ Loading Whisper model ({args.model})...")
#             model = whisper.load_model(args.model)
#             print("‚úÖ Model loaded")
#             print()
            
#             # Convert
#             audio_to_text(
#                 audio_path=args.path,
#                 output_path=args.output_file,
#                 model=model,
#                 quiet=False
#             )
            
#             print()
#             print("="*60)
#             print("‚ú® HO√ÄN TH√ÄNH!")
#             print("="*60)
            
#             return 0
        
#     except FileNotFoundError as e:
#         logger.error(f"\n‚ùå L·ªói: {e}")
#         return 1
#     except Exception as e:
#         logger.error(f"\n‚ùå L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}")
#         import traceback
#         traceback.print_exc()
#         return 1


# if __name__ == "__main__":
#     sys.exit(main())
