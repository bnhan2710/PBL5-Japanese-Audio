"""
JLPT Audio Splitter - T√°ch file audio JLPT th√†nh mondai v√† c√¢u h·ªèi t·ª± ƒë·ªông

C√¥ng ngh·ªá s·ª≠ d·ª•ng:
- Google Gemini: AI ph√¢n t√≠ch c·∫•u tr√∫c (FREE)
- FFmpeg: Audio processing v√† c·∫Øt file (thay PyDub)

"""

import whisper
import json
import logging
import subprocess
from pathlib import Path
import os
from typing import Dict, List, Optional, Tuple
from dotenv import load_dotenv
import google.generativeai as genai
from datetime import datetime

# Load environment variables
load_dotenv()

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('audio_splitter.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class JPLTAudioSplitter:
    """
    Class x·ª≠ l√Ω t√°ch file audio JLPT th√†nh c√°c mondai v√† c√¢u h·ªèi
    
    Pipeline:
    1. Transcribe audio v·ªõi Whisper (l·∫•y text + timestamps)
    2. Ph√¢n t√≠ch c·∫•u tr√∫c v·ªõi Gemini AI (t√¨m mondai v√† c√¢u h·ªèi)
    3. C·∫Øt audio d·ª±a tr√™n timestamps (t·∫°o file ri√™ng)
    """
    
    def __init__(
        self, 
        audio_path: str, 
        output_dir: str = "output",
        whisper_model_size: str = "base",
        image_path: Optional[str] = None
    ):
        """
        Kh·ªüi t·∫°o JLPT Audio Splitter
        
        Args:
            audio_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file audio JLPT (.mp3, .wav, .m4a, etc)
            output_dir: Th∆∞ m·ª•c output (m·∫∑c ƒë·ªãnh: "output")
            whisper_model_size: K√≠ch th∆∞·ªõc model Whisper (tiny/base/small/medium/large)
            image_path: ƒê∆∞·ªùng d·∫´n file ·∫£nh ƒë·ªÅ thi (optional, ƒë·ªÉ AI ph√¢n t√≠ch th√™m)
        
        Raises:
            FileNotFoundError: N·∫øu audio file kh√¥ng t·ªìn t·∫°i
            ValueError: N·∫øu thi·∫øu GOOGLE_API_KEY
        """
        logger.info("üöÄ Kh·ªüi t·∫°o JLPT Audio Splitter")
        
        # Validate audio file
        self.audio_path = Path(audio_path)
        if not self.audio_path.exists():
            raise FileNotFoundError(f"‚ùå File audio kh√¥ng t·ªìn t·∫°i: {audio_path}")
        logger.info(f"üìÅ Audio file: {self.audio_path}")
        
        # Setup paths
        self.image_path = Path(image_path) if image_path else None
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True, parents=True)
        logger.info(f"üìÇ Output directory: {self.output_dir.absolute()}")
        
        # Load Whisper model
        self.whisper_model_size = whisper_model_size
        logger.info(f"üîÑ ƒêang load Whisper model ({whisper_model_size})...")
        try:
            self.whisper_model = whisper.load_model(whisper_model_size)
            logger.info("‚úÖ Whisper model loaded")
        except Exception as e:
            logger.error(f"‚ùå L·ªói load Whisper model: {e}")
            raise
        
        # Setup Google Gemini
        logger.info("üîÑ ƒêang setup Google Gemini API...")
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            error_msg = (
                "‚ùå GOOGLE_API_KEY kh√¥ng t√¨m th·∫•y!\n"
                "üìù H∆∞·ªõng d·∫´n l·∫•y FREE API key:\n"
                "   1. Truy c·∫≠p: https://makersuite.google.com/app/apikey\n"
                "   2. ƒêƒÉng nh·∫≠p Google account\n"
                "   3. T·∫°o API key m·ªõi\n"
                "   4. L∆∞u v√†o file .env: GOOGLE_API_KEY=your_key_here"
            )
            logger.error(error_msg)
            raise ValueError(error_msg)
        
        genai.configure(api_key=api_key)
        self.ai_client = genai.GenerativeModel('gemini-2.5-flash')
        logger.info("‚úÖ Google Gemini configured (FREE tier)")
        
        # Stats
        self.stats = {
            "start_time": datetime.now(),
            "transcript_time": None,
            "analysis_time": None,
            "split_time": None,
            "total_mondai": 0,
            "total_questions": 0
        }
    
    def transcribe_audio(self) -> Dict:
        """
        B∆∞·ªõc 1: Transcribe audio file th√†nh text v·ªõi timestamps chi ti·∫øt
        
        S·ª≠ d·ª•ng OpenAI Whisper ƒë·ªÉ:
        - Chuy·ªÉn audio th√†nh text (Japanese)
        - L·∫•y timestamps cho t·ª´ng segment v√† word
        - L∆∞u k·∫øt qu·∫£ v√†o transcript.json
        
        Returns:
            Dict ch·ª©a transcript v·ªõi segments v√† timestamps
            
        Raises:
            Exception: N·∫øu transcribe th·∫•t b·∫°i
        """
        logger.info("="*60)
        logger.info("üìù B∆Ø·ªöC 1: TRANSCRIBE AUDIO")
        logger.info("="*60)
        
        start_time = datetime.now()
        logger.info(f"üé§ ƒêang transcribe: {self.audio_path.name}")
        logger.info(f"‚è±Ô∏è  Whisper model: {self.whisper_model_size}")
        
        try:
            result = self.whisper_model.transcribe(
                str(self.audio_path),
                language="ja",  # Japanese
                task="transcribe",
                verbose=False,  # T·∫Øt verbose ƒë·ªÉ log s·∫°ch h∆°n
                word_timestamps=True  # Quan tr·ªçng: timestamps t·ª´ng word
            )
            
            # L∆∞u transcript
            transcript_path = self.output_dir / "transcript.json"
            with open(transcript_path, "w", encoding="utf-8") as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            elapsed = (datetime.now() - start_time).total_seconds()
            self.stats["transcript_time"] = elapsed
            
            logger.info(f"‚úÖ Transcribe ho√†n th√†nh trong {elapsed:.1f}s")
            logger.info(f"üìÑ Transcript saved: {transcript_path}")
            logger.info(f"üìä T·ªïng segments: {len(result['segments'])}")
            logger.info(f"üìä ƒê·ªô d√†i audio: {result['segments'][-1]['end']:.1f}s")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói transcribe audio: {e}")
            raise
    
    def analyze_structure_with_ai(self, transcript: Dict) -> Dict:
        """
        B∆∞·ªõc 2: S·ª≠ d·ª•ng Gemini AI ƒë·ªÉ ph√¢n t√≠ch c·∫•u tr√∫c ƒë·ªÅ thi
        
        AI s·∫Ω:
        - T√¨m c√°c MONDAI (ÂïèÈ°å) markers
        - X√°c ƒë·ªãnh boundaries gi·ªØa c√°c mondai
        - T√¨m c√¢u h·ªèi trong m·ªói mondai („ÅÑ„Å°„Å∞„Çì, „Å´„Å∞„Çì, ...)
        - Tr·∫£ v·ªÅ structure v·ªõi timestamps ch√≠nh x√°c
        
        Args:
            transcript: K·∫øt qu·∫£ t·ª´ Whisper
            
        Returns:
            Dict ch·ª©a c·∫•u tr√∫c mondai v√† questions v·ªõi timestamps
            
        Raises:
            Exception: N·∫øu AI analysis ho·∫∑c JSON parsing th·∫•t b·∫°i
        """
        logger.info("\n" + "="*60)
        logger.info("ü§ñ B∆Ø·ªöC 2: PH√ÇN T√çCH C·∫§U TR√öC V·ªöI AI")
        logger.info("="*60)
        
        start_time = datetime.now()
        
        # Chu·∫©n b·ªã transcript cho AI
        segments_text = "\n".join([
            f"[{seg['start']:.2f}s - {seg['end']:.2f}s] {seg['text']}"
            for seg in transcript['segments']
        ])
        
        logger.info(f"üìù Preparing prompt v·ªõi {len(transcript['segments'])} segments")
        
        # Prompt cho Gemini
        prompt = f"""B·∫°n l√† chuy√™n gia ph√¢n t√≠ch ƒë·ªÅ thi JLPT. Nhi·ªám v·ª• c·ªßa b·∫°n l√† ph√¢n t√≠ch transcript audio ƒë·ªÉ x√°c ƒë·ªãnh c·∫•u tr√∫c ƒë·ªÅ thi.

TRANSCRIPT V·ªöI TIMESTAMPS:
{segments_text}

Y√äU C·∫¶U:
1. T√¨m c√°c MONDAI (ÂïèÈ°å) - ph·∫ßn l·ªõn c·ªßa ƒë·ªÅ thi
   - Markers: "„ÇÇ„Çì„Å†„ÅÑ" (mondai), "ÂïèÈ°å", ho·∫∑c s·ªë th·ª© t·ª± mondai
   
2. T√¨m c√°c c√¢u h·ªèi trong m·ªói mondai
   - Markers: "„ÅÑ„Å°„Å∞„Çì" (1), "„Å´„Å∞„Çì" (2), "„Åï„Çì„Å∞„Çì" (3), "„Çà„Çì„Å∞„Çì" (4), "„Åî„Å∞„Çì" (5)...
   - "„Å∞„Çì" (ban) = s·ªë th·ª© t·ª± c√¢u h·ªèi
   - Th∆∞·ªùng c√≥ pause/kho·∫£ng l·∫∑ng gi·ªØa c√°c c√¢u h·ªèi
   - ƒêi·ªÉm c·∫ßn c·∫Øt ƒë√≥ l√† khi c√≥ marker s·ªë + "„Å∞„Çì" (ban) v√† tr∆∞·ªõc ƒë√≥ l√† ti·∫øng chu√¥ng
   - C√°c c√¢u h·ªèi trong c√πng m·ªôt mondai s·∫Ω c√≥ th·ªùi l∆∞·ª£ng gi·ªëng nhau
   - C√°c file ƒë·ªÅ JLPT N1, N2 ·ªü Mondai 5 (g·∫ßn cu·ªëi b√†i nghe) s·∫Ω c√≥ 2 "„Åó„Å§„ÇÇ„Çì" n·∫±m trong m·ªôt ƒëo·∫°n h·ªôi tho·∫°i v√† kh√¥ng ƒë∆∞·ª£c c·∫Øt audio t·∫°i ƒë√¢y. Ch·ªâ ƒë∆∞·ª£c c·∫Øt n·∫øu c√≥ ch·ªØ ‚ÄùÁï™‚Äù.
3. X√°c ƒë·ªãnh timestamps ch√≠nh x√°c cho:
   - B·∫Øt ƒë·∫ßu v√† k·∫øt th√∫c m·ªói mondai
   - B·∫Øt ƒë·∫ßu v√† k·∫øt th√∫c m·ªói c√¢u h·ªèi

OUTPUT FORMAT (JSON ONLY):
{{
  "mondai": [
    {{
      "mondai_number": 1,
      "title": "Mondai 1",
      "start_time": 0.0,
      "end_time": 120.5,
      "questions": [
        {{
          "question_number": 1,
          "start_time": 0.0,
          "end_time": 15.5,
          "text": "Excerpt c·ªßa c√¢u h·ªèi n·∫øu c√≥"
        }}
      ]
    }}
  ]
}}

L∆ØU √ù:
- Tr·∫£ v·ªÅ ONLY valid JSON, kh√¥ng th√™m text gi·∫£i th√≠ch
- Timestamps ph·∫£i ch√≠nh x√°c d·ª±a tr√™n transcript
- N·∫øu kh√¥ng ch·∫Øc ch·∫Øn, ∆∞·ªõc l∆∞·ª£ng d·ª±a tr√™n pause v√† context
- M·ªói mondai ph·∫£i c√≥ √≠t nh·∫•t 1 question"""

        try:
            logger.info("üåê ƒêang g·ªçi Gemini API...")
            response = self.ai_client.generate_content(prompt)
            result_text = response.text
            
            logger.info("‚úÖ Nh·∫≠n response t·ª´ Gemini")
            
            # Parse JSON from response
            result_text = self._extract_json_from_text(result_text)
            structure = json.loads(result_text)
            
            # Validate structure
            self._validate_structure(structure)
            
            # L∆∞u structure
            structure_path = self.output_dir / "structure.json"
            with open(structure_path, "w", encoding="utf-8") as f:
                json.dump(structure, f, ensure_ascii=False, indent=2)
            
            elapsed = (datetime.now() - start_time).total_seconds()
            self.stats["analysis_time"] = elapsed
            
            # Statistics
            total_mondai = len(structure['mondai'])
            total_questions = sum(len(m['questions']) for m in structure['mondai'])
            self.stats["total_mondai"] = total_mondai
            self.stats["total_questions"] = total_questions
            
            logger.info(f"‚úÖ Ph√¢n t√≠ch ho√†n th√†nh trong {elapsed:.1f}s")
            logger.info(f"üìÑ Structure saved: {structure_path}")
            logger.info(f"üìä T·ªïng mondai: {total_mondai}")
            logger.info(f"üìä T·ªïng c√¢u h·ªèi: {total_questions}")
            
            # Log chi ti·∫øt t·ª´ng mondai
            for mondai in structure['mondai']:
                logger.info(
                    f"   Mondai {mondai['mondai_number']}: "
                    f"{len(mondai['questions'])} c√¢u h·ªèi "
                    f"({mondai['start_time']:.1f}s - {mondai['end_time']:.1f}s)"
                )
            
            return structure
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå L·ªói parse JSON: {e}")
            logger.error(f"Response t·ª´ AI: {result_text[:500]}...")
            raise
        except Exception as e:
            logger.error(f"‚ùå L·ªói ph√¢n t√≠ch v·ªõi AI: {e}")
            raise
    
    def _extract_json_from_text(self, text: str) -> str:
        """
        Tr√≠ch xu·∫•t JSON t·ª´ response text (c√≥ th·ªÉ c√≥ markdown code blocks)
        
        Args:
            text: Response text t·ª´ AI
            
        Returns:
            Clean JSON string
        """
        # Remove markdown code blocks
        if "```json" in text:
            text = text.split("```json")[1].split("```")[0].strip()
        elif "```" in text:
            text = text.split("```")[1].split("```")[0].strip()
        
        return text.strip()
    
    def _validate_structure(self, structure: Dict) -> None:
        """
        Validate structure t·ª´ AI
        
        Args:
            structure: Structure dict c·∫ßn validate
            
        Raises:
            ValueError: N·∫øu structure kh√¥ng h·ª£p l·ªá
        """
        if "mondai" not in structure:
            raise ValueError("Structure thi·∫øu key 'mondai'")
        
        if not structure["mondai"]:
            raise ValueError("Structure kh√¥ng c√≥ mondai n√†o")
        
        for i, mondai in enumerate(structure["mondai"]):
            required_keys = ["mondai_number", "start_time", "end_time", "questions"]
            for key in required_keys:
                if key not in mondai:
                    raise ValueError(f"Mondai {i+1} thi·∫øu key '{key}'")
            
            if not mondai["questions"]:
                raise ValueError(f"Mondai {i+1} kh√¥ng c√≥ c√¢u h·ªèi n√†o")
            
            for j, question in enumerate(mondai["questions"]):
                required_q_keys = ["question_number", "start_time", "end_time"]
                for key in required_q_keys:
                    if key not in question:
                        raise ValueError(
                            f"Mondai {i+1}, Question {j+1} thi·∫øu key '{key}'"
                        )
    
    def split_audio(self, structure: Dict) -> None:
        """
        B∆∞·ªõc 3: C·∫Øt audio file th√†nh c√°c mondai v√† c√¢u h·ªèi ri√™ng bi·ªát
        
        D·ª±a v√†o timestamps t·ª´ AI analysis:
        - T·∫°o file MP3 ri√™ng cho m·ªói mondai
        - T·∫°o file MP3 ri√™ng cho m·ªói c√¢u h·ªèi trong mondai
        - Organize theo th∆∞ m·ª•c: mondai/mondai_X/question_Y.mp3
        
        S·ª≠ d·ª•ng FFmpeg tr·ª±c ti·∫øp thay v√¨ PyDub (Python 3.13 compatible)
        
        Args:
            structure: Structure dict t·ª´ AI analysis
            
        Raises:
            Exception: N·∫øu audio processing th·∫•t b·∫°i
        """
        logger.info("\n" + "="*60)
        logger.info("‚úÇÔ∏è  B∆Ø·ªöC 3: C·∫ÆT AUDIO (FFmpeg)")
        logger.info("="*60)
        
        start_time = datetime.now()
        
        try:
            # T·∫°o th∆∞ m·ª•c mondai
            mondai_dir = self.output_dir / "mondai"
            mondai_dir.mkdir(exist_ok=True, parents=True)
            
            # C·∫Øt t·ª´ng mondai
            for mondai_info in structure['mondai']:
                mondai_num = mondai_info['mondai_number']
                logger.info(f"\nüìå ƒêang x·ª≠ l√Ω Mondai {mondai_num}...")
                
                # Extract mondai audio v·ªõi FFmpeg
                start_time_sec = mondai_info['start_time']
                duration_sec = mondai_info['end_time'] - mondai_info['start_time']
                
                # T·∫°o th∆∞ m·ª•c cho mondai n√†y
                mondai_subdir = mondai_dir / f"mondai_{mondai_num}"
                mondai_subdir.mkdir(exist_ok=True, parents=True)
                
                mondai_path = mondai_subdir / f"mondai_{mondai_num}.mp3"
                
                # FFmpeg command to extract audio segment (only audio stream)
                cmd = [
                    'ffmpeg',
                    '-i', str(self.audio_path),
                    '-ss', str(start_time_sec),
                    '-t', str(duration_sec),
                    '-vn',  # No video (skip album art/image)
                    '-acodec', 'libmp3lame',
                    '-b:a', '192k',
                    '-y',  # Overwrite output file
                    str(mondai_path)
                ]
                
                result = subprocess.run(cmd, capture_output=True, text=True)
                if result.returncode != 0:
                    logger.error(f"‚ùå FFmpeg error: {result.stderr}")
                    raise RuntimeError(f"FFmpeg failed for mondai {mondai_num}")
                
                logger.info(
                    f"‚úÖ Mondai {mondai_num}: {mondai_path.name} "
                    f"({duration_sec:.1f}s)"
                )
                
                # T·∫°o th∆∞ m·ª•c questions b√™n trong mondai
                questions_dir = mondai_subdir / "questions"
                questions_dir.mkdir(exist_ok=True, parents=True)
                
                # C·∫Øt t·ª´ng question
                for question_info in mondai_info['questions']:
                    q_num = question_info['question_number']
                    q_start_sec = question_info['start_time']
                    q_duration_sec = question_info['end_time'] - question_info['start_time']
                    
                    question_path = questions_dir / f"question_{q_num}.mp3"
                    
                    # FFmpeg command for question (only audio stream)
                    cmd = [
                        'ffmpeg',
                        '-i', str(self.audio_path),
                        '-ss', str(q_start_sec),
                        '-t', str(q_duration_sec),
                        '-vn',  # No video
                        '-acodec', 'libmp3lame',
                        '-b:a', '192k',
                        '-y',
                        str(question_path)
                    ]
                    
                    result = subprocess.run(cmd, capture_output=True, text=True)
                    if result.returncode != 0:
                        logger.error(f"‚ùå FFmpeg error: {result.stderr}")
                        raise RuntimeError(f"FFmpeg failed for question {q_num}")
                    
                    logger.info(
                        f"   ‚úÖ Question {q_num}: {question_path.name} "
                        f"({q_duration_sec:.1f}s)"
                    )
            
            elapsed = (datetime.now() - start_time).total_seconds()
            self.stats["split_time"] = elapsed
            
            logger.info(f"\n‚úÖ C·∫Øt audio ho√†n th√†nh trong {elapsed:.1f}s")
            logger.info(f"üìÅ Output directory: {mondai_dir.absolute()}")
            logger.info(f"\nüí° C·∫•u tr√∫c output:")
            logger.info(f"   output/mondai/")
            logger.info(f"   ‚îú‚îÄ‚îÄ mondai_1/")
            logger.info(f"   ‚îÇ   ‚îú‚îÄ‚îÄ mondai_1.mp3")
            logger.info(f"   ‚îÇ   ‚îî‚îÄ‚îÄ questions/")
            logger.info(f"   ‚îÇ       ‚îú‚îÄ‚îÄ question_1.mp3")
            logger.info(f"   ‚îÇ       ‚îî‚îÄ‚îÄ ...")
            logger.info(f"   ‚îî‚îÄ‚îÄ ...")
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói c·∫Øt audio: {e}")
            raise
    
    def process(self) -> Dict:
        """
        Ch·∫°y to√†n b·ªô pipeline x·ª≠ l√Ω
        
        Pipeline:
        1. Transcribe audio ‚Üí text + timestamps
        2. Analyze structure ‚Üí t√¨m mondai + questions
        3. Split audio ‚Üí t·∫°o file ri√™ng
        
        Returns:
            Dict ch·ª©a statistics c·ªßa qu√° tr√¨nh x·ª≠ l√Ω
            
        Raises:
            Exception: N·∫øu b·∫•t k·ª≥ b∆∞·ªõc n√†o th·∫•t b·∫°i
        """
        logger.info("\n" + "="*70)
        logger.info("üöÄ B·∫ÆT ƒê·∫¶U X·ª¨ L√ù JLPT AUDIO")
        logger.info("="*70)
        logger.info(f"üìÅ Input: {self.audio_path.name}")
        logger.info(f"üìÇ Output: {self.output_dir.absolute()}")
        logger.info(f"ü§ñ AI: Google Gemini 1.5 Flash (FREE)")
        logger.info(f"üé§ Whisper: {self.whisper_model_size}")
        logger.info("="*70)
        
        try:
            # B∆∞·ªõc 1: Transcribe
            transcript = self.transcribe_audio()
            
            # B∆∞·ªõc 2: Analyze
            structure = self.analyze_structure_with_ai(transcript)
            
            # B∆∞·ªõc 3: Split
            self.split_audio(structure)
            
            # Calculate total time
            total_time = (datetime.now() - self.stats["start_time"]).total_seconds()
            
            # Print summary
            logger.info("\n" + "="*70)
            logger.info("‚ú® HO√ÄN TH√ÄNH!")
            logger.info("="*70)
            logger.info(f"‚è±Ô∏è  T·ªïng th·ªùi gian: {total_time:.1f}s")
            logger.info(f"   - Transcribe: {self.stats['transcript_time']:.1f}s")
            logger.info(f"   - AI Analysis: {self.stats['analysis_time']:.1f}s")
            logger.info(f"   - Split Audio: {self.stats['split_time']:.1f}s")
            logger.info(f"üìä K·∫øt qu·∫£:")
            logger.info(f"   - {self.stats['total_mondai']} mondai")
            logger.info(f"   - {self.stats['total_questions']} c√¢u h·ªèi")
            logger.info(f"üìÅ Output: {self.output_dir.absolute()}")
            logger.info("="*70)
            
            return self.stats
            
        except Exception as e:
            logger.error(f"\n‚ùå X·ª¨ L√ù TH·∫§T B·∫†I: {e}")
            raise


def main():
    import sys
    
    # Check command line arguments
    if len(sys.argv) > 1:
        audio_path = sys.argv[1]
        output_dir = sys.argv[2] if len(sys.argv) > 2 else "output"
    else:
        # Demo v·ªõi file JLPT N2
        audio_path = "data/jlpt_n2.mp3"
        output_dir = "output"
        
        print("üí° C√°ch s·ª≠ d·ª•ng:")
        print(f"   python {__file__} <audio_path> [output_dir]")
        print(f"\nV√≠ d·ª•:")
        print(f"   python {__file__} input/jlpt_n2.mp3")
        print(f"   python {__file__} input/jlpt_n2.mp3 my_output")
        print("\nüéØ ƒêang ch·∫°y v·ªõi file: {audio_path}")
        print("="*70)
    
    try:
        # Kh·ªüi t·∫°o v√† ch·∫°y
        splitter = JPLTAudioSplitter(
            audio_path=audio_path,
            output_dir=output_dir,
            whisper_model_size="base"  # tiny/base/small/medium/large
        )
        
        stats = splitter.process()
        
        # Success
        return 0
        
    except FileNotFoundError as e:
        logger.error(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {e}")
        return 1
    except ValueError as e:
        logger.error(f"‚ùå L·ªói c·∫•u h√¨nh: {e}")
        return 1
    except Exception as e:
        logger.error(f"‚ùå L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}", exc_info=True)
        return 1


if __name__ == "__main__":
    exit(main())